

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>API &mdash; adadamp  documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/basic.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="Experiments" href="experiments.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> adadamp
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="basic-usage.html">Basic Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="math.html">Mathematical underpinnings</a></li>
<li class="toctree-l1"><a class="reference internal" href="experiments.html">Experiments</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">API</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">adadamp</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>API</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/api.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">

           <div itemprop="articleBody">
            
  <div class="section" id="module-adadamp">
<span id="api"></span><h1>API<a class="headerlink" href="#module-adadamp" title="Permalink to this headline">¶</a></h1>
<dl class="class">
<dt id="adadamp.BaseDamper">
<em class="property">class </em><code class="sig-prename descclassname">adadamp.</code><code class="sig-name descname">BaseDamper</code><span class="sig-paren">(</span><em class="sig-param">model: torch.nn.modules.module.Module</em>, <em class="sig-param">dataset: torch.utils.data.dataset.Dataset</em>, <em class="sig-param">opt: torch.optim.optimizer.Optimizer</em>, <em class="sig-param">loss: Callable = &lt;function nll_loss&gt;</em>, <em class="sig-param">initial_batch_size: int = 1</em>, <em class="sig-param">device: str = 'cpu'</em>, <em class="sig-param">max_batch_size: Union[float</em>, <em class="sig-param">int</em>, <em class="sig-param">None] = None</em>, <em class="sig-param">best_train_loss: Optional[float] = None</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#adadamp.BaseDamper" title="Permalink to this definition">¶</a></dt>
<dd><p>Damp the noise in the gradient estimate.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>nn.Module</em>) – The model to train</p></li>
<li><p><strong>dataset</strong> (<em>torch.Dataset</em>) – Dataset to use for training</p></li>
<li><p><strong>opt</strong> (<em>torch.optim.Optimizer</em>) – The optimizer to use</p></li>
<li><p><strong>loss</strong> (<em>callable</em><em> (</em><em>function</em><em>)</em><em>, </em><em>default=torch.nn.F.nll_loss</em>) – The loss function to use. Must support the reduction keyword. Signature:
<code class="docutils literal notranslate"><span class="pre">loss(output,</span> <span class="pre">target,</span> <span class="pre">reduction=&quot;sum&quot;)</span></code>.</p></li>
<li><p><strong>initial_batch_size</strong> (<em>int</em><em>, </em><em>default=1</em>) – Initial batch size</p></li>
<li><p><strong>device</strong> (<em>str</em><em>, </em><em>default=&quot;cpu&quot;</em>) – The device to use.</p></li>
<li><p><strong>max_batch_size</strong> (<em>int</em><em>, </em><em>float</em><em>, </em><em>None</em><em>, </em><em>default=None</em>) – The maximum batch size. If the batch size is larger than this
value, the learning rate is decayed by an appropriate amount.
If None, will automatically be set to be the size of the
dataset. Setting to NaN will result in no maximum batch size.</p></li>
<li><p><strong>kwargs</strong> (<em>dict</em>) – Arguments to pass to the underlying torch.DataLoader</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>By default, this class does not perform any damping (but it’s children
do). If a function needs an instance of BaseDamper, this class can wrap
any optimizer.</p>
<dl class="method">
<dt id="adadamp.BaseDamper.damping">
<code class="sig-name descname">damping</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; int<a class="headerlink" href="#adadamp.BaseDamper.damping" title="Permalink to this definition">¶</a></dt>
<dd><p>Determines how strongly noise in stochastic gradient
estimate is damped.</p>
<p class="rubric">Notes</p>
<p>This is the main function for subclasses to overwrite. By
default, this wraps an optimizer with a static
<code class="docutils literal notranslate"><span class="pre">self.initial_batch_size</span></code>. Here’s a brief example usage:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">dataset</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">AdaGrad</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt</span> <span class="o">=</span> <span class="n">BaseDamper</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">opt</span><span class="p">,</span> <span class="n">initial_batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt</span><span class="o">.</span><span class="n">damping</span><span class="p">()</span>
<span class="go">32</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="adadamp.BaseDamper.get_params">
<code class="sig-name descname">get_params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#adadamp.BaseDamper.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get parameters for this optimzer.</p>
</dd></dl>

<dl class="method">
<dt id="adadamp.BaseDamper.meta">
<em class="property">property </em><code class="sig-name descname">meta</code><a class="headerlink" href="#adadamp.BaseDamper.meta" title="Permalink to this definition">¶</a></dt>
<dd><p>Get meta information about this optimizer, including number
of model updates and number of examples processed.</p>
</dd></dl>

<dl class="method">
<dt id="adadamp.BaseDamper.step">
<code class="sig-name descname">step</code><span class="sig-paren">(</span><em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#adadamp.BaseDamper.step" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform an optimization step</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em><em>, </em><em>optional</em>) – Arguments to pass to PyTorch’s <code class="docutils literal notranslate"><span class="pre">opt.step</span></code>
(e.g., <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.optim.AdaGrad</span></code>)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="adadamp.AdaDamp">
<em class="property">class </em><code class="sig-prename descclassname">adadamp.</code><code class="sig-name descname">AdaDamp</code><span class="sig-paren">(</span><em class="sig-param">*args</em>, <em class="sig-param">approx_loss=False</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#adadamp.AdaDamp" title="Permalink to this definition">¶</a></dt>
<dd><dl class="method">
<dt id="adadamp.AdaDamp.damping">
<code class="sig-name descname">damping</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; int<a class="headerlink" href="#adadamp.AdaDamp.damping" title="Permalink to this definition">¶</a></dt>
<dd><p>Adaptively damp the noise depending on the current loss with</p>
<div class="math notranslate nohighlight">
\[B_k = \left\lceil B_0\frac{F(x_0) - F^\star}{F(x_k) - F^\star}\right\rceil\]</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>This batch size is expensive to compute. It requires evaluating the entire loss function <span class="math notranslate nohighlight">\(F\)</span>. Use of
<a class="reference internal" href="#adadamp.PadaDamp" title="adadamp.PadaDamp"><code class="xref py py-class docutils literal notranslate"><span class="pre">PadaDamp</span></code></a> is recommended.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="adadamp.PadaDamp">
<em class="property">class </em><code class="sig-prename descclassname">adadamp.</code><code class="sig-name descname">PadaDamp</code><span class="sig-paren">(</span><em class="sig-param">*args</em>, <em class="sig-param">batch_growth_rate=None</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#adadamp.PadaDamp" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>args</strong> (<em>list</em>) – Passed to BaseDamper</p></li>
<li><p><strong>batch_growth_rate</strong> (<em>float</em>) – <p>The rate to increase the damping by. That is, set the batch size
to be</p>
<div class="math notranslate nohighlight">
\[B_k = B_0 \lceil \textrm{rate}\cdot k \rceil\]</div>
<p>after the model is updated <span class="math notranslate nohighlight">\(k\)</span> times.</p>
</p></li>
<li><p><strong>kwargs</strong> (<em>dict</em>) – Passed to BaseDamper</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The number of epochs is</p>
<div class="math notranslate nohighlight">
\[uB_0 + \sum_{i=1}^u \lceil \textrm{rate} \cdot k\rceil\]</div>
<p>for <span class="math notranslate nohighlight">\(u\)</span> model updates.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This class is only appropriate for non-convex and convex loss
functions. It is not appropriate for strongly convex loss or PL
functions.</p>
</div>
<dl class="method">
<dt id="adadamp.PadaDamp.damping">
<code class="sig-name descname">damping</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; int<a class="headerlink" href="#adadamp.PadaDamp.damping" title="Permalink to this definition">¶</a></dt>
<dd><p>Approximate AdaDamp with less computation via</p>
<div class="math notranslate nohighlight">
\[B_k = B_0 + \lceil \textrm{rate}\cdot k\rceil\]</div>
<p>where k is the number of model updates.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="adadamp.GeoDamp">
<em class="property">class </em><code class="sig-prename descclassname">adadamp.</code><code class="sig-name descname">GeoDamp</code><span class="sig-paren">(</span><em class="sig-param">*args</em>, <em class="sig-param">dampingdelay=5</em>, <em class="sig-param">dampingfactor=2</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#adadamp.GeoDamp" title="Permalink to this definition">¶</a></dt>
<dd><dl class="method">
<dt id="adadamp.GeoDamp.damping">
<code class="sig-name descname">damping</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; int<a class="headerlink" href="#adadamp.GeoDamp.damping" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the batch size to increase by <code class="docutils literal notranslate"><span class="pre">dampingfactor</span></code> every
<code class="docutils literal notranslate"><span class="pre">dampingdelay</span></code> epochs.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="adadamp.GeoDampLR">
<em class="property">class </em><code class="sig-prename descclassname">adadamp.</code><code class="sig-name descname">GeoDampLR</code><span class="sig-paren">(</span><em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#adadamp.GeoDampLR" title="Permalink to this definition">¶</a></dt>
<dd><dl class="method">
<dt id="adadamp.GeoDampLR.damping">
<code class="sig-name descname">damping</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; int<a class="headerlink" href="#adadamp.GeoDampLR.damping" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the learning rate to decrease by <code class="docutils literal notranslate"><span class="pre">dampingfactor</span></code> every
<code class="docutils literal notranslate"><span class="pre">dampingdelay</span></code> epochs.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="adadamp.CntsDampLR">
<em class="property">class </em><code class="sig-prename descclassname">adadamp.</code><code class="sig-name descname">CntsDampLR</code><span class="sig-paren">(</span><em class="sig-param">*args</em>, <em class="sig-param">dampingfactor=0.02</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#adadamp.CntsDampLR" title="Permalink to this definition">¶</a></dt>
<dd><dl class="method">
<dt id="adadamp.CntsDampLR.damping">
<code class="sig-name descname">damping</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; int<a class="headerlink" href="#adadamp.CntsDampLR.damping" title="Permalink to this definition">¶</a></dt>
<dd><p>Decay the learning rate by <span class="math notranslate nohighlight">\(1/k\)</span> after <span class="math notranslate nohighlight">\(k\)</span> model updates.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="adadamp.GradientDescent">
<em class="property">class </em><code class="sig-prename descclassname">adadamp.</code><code class="sig-name descname">GradientDescent</code><span class="sig-paren">(</span><em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#adadamp.GradientDescent" title="Permalink to this definition">¶</a></dt>
<dd><p>This class performs full gradient descent.</p>
<dl class="method">
<dt id="adadamp.GradientDescent.damping">
<code class="sig-name descname">damping</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; int<a class="headerlink" href="#adadamp.GradientDescent.damping" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>


           </div>
           
          </div>
      <a href="https://github.com/stsievert/adadamp">
        <img style="position: absolute; top: 0; right: 0; border: 0;" src="https://github.blog/wp-content/uploads/2008/12/forkme_right_gray_6d6d6d.png?resize=149%2C149" alt="Fork me on GitHub">
    </a>

          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
      
        <a href="experiments.html" class="btn btn-neutral float-left" title="Experiments" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020, Scott Sievert

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>